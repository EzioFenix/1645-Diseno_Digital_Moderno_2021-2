```json
{
    'nombre': 'Barrera Peña  Víctor Miguel',
    'tipo': 'Tarea',
    'no': '17',
    'grupo':  '6',
    'materia': '1645 Diseño Digital Moderno',
    'semestre': '2022-1',
    'enunciado': 'Realizar una  investigación: EBCDIC',
    'fecha': '21-09-2021'
}
```

<style>
    body{
  text-align: justify;
}
    h1{
        font-weight: bold;
        text-align:center;
    }
    p::first-letter{
  font-size: 1.3rem;
}
 a{
  text-decoration: none;
}
</style>
# Realizar una  investigación: EBCDIC

El estándar conformado por hoy por Unicode tiene una historia bastante larga.

IBM tenía una vez formatos de comunicación, uno de los cuales prevaleció sobre los otros para evitar menos problemas y este fue llamado EBCDIC(Extended Binary Coded Decimal Interchange Code).

Tiempo después surgió un formato llamado a ASCII, las compañías tenían preocupación sobre la compatibilidad de dichos productos, por ello se llamó al juego a ANSI. Quién reguló los controles para que todo fuera de una manera compatible, se puso ciertas restricciones, lo que benefició a ANSI, ya que éste era mucho más fácil de implementar dichas mejoras, era más eficiente y tenía algunas cosas, por ejemplo, la diferencia entre un carácter en mayúscula y una minúscula es sólo de un bit, ante los humanos eso es mucho más simple.

Para 1964 se planteó sacar un nuevo modelo por parte de IBM llamado System 360. Los ingenieros de dicha máquina trabajaron para implementar a ASCII y que pudiera funcionar, sin embargo bajo el estándar de ASCII se terminó en 1963 y no les dio el tiempo suficiente para implementarlo y poseer interoperabilidad entre ambas formas de representación, esto fue un calvario para que el que comprara el sistema.

En 1981 por fin IBM sacaba su modelo con a ASCII, este fue muy bien aceptado por el público y se vendió en masas, sin embargo, ahora existía un nuevo problema, la implementación de ASCII era buena, pero la mayoría de las computadoras utilizaban 8 bits para comunicarse aquí está sólo utilizaba 7, por lo tanto, tenía un bit más, lo que les daría 256 representaciones y no podían abarcar todos los lenguajes conocidos.

En 1991 se puso a trabajar en un nuevo estándar (Unicode) qué haría más fácil la comunicación entre diferentes computadoras, este era mucho más largo que sus antecesores, sin embargo, para ese periodo ya no estaba tan penalizada el uso de pequeños segmentos de memoria, ya que el avance tecnológico lo permitía. Este estándar fue y es el más grande que ha existido, es capaz de albergar mucha más información y se actualiza año tras año, para el momento actual las versiones 9.0 capaz de almacenar 120,000 caracteres incluyendo, emojis, representación del lenguaje chino y hasta jeroglíficos.

Podríamos ver que, con este pequeño resumen, el estándar que fundó IBM fracaso y mejor se sustituyó por ASCII.

EBCIDIC

![Lo basico sobre computadoras: EBCDIC (Extendido de Caracteres Decimales  Codificados en Binario para el Intercambio de Información)](http://1.bp.blogspot.com/-mfm1ZYlvS4c/VZ6XLXBLRhI/AAAAAAAAACs/ENC6JApMqR0/s1600/screenB-1.gif)



# Referencias

- The Science Elf. (2017, 14 enero). *Format Wars: ASCII vs EBCDIC*. YouTube. https://www.youtube.com/watch?v=3kXLHLUhV5Q
